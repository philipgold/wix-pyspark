{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks:\n",
    "* Create custom schema for json files\n",
    "* Read files \n",
    "* Add new column via UDF - timestamp \n",
    "* Add new column - Solder's High salary \n",
    "* Rename column \n",
    "* Append rows (contatinatin) \n",
    "* Join all file types \n",
    "* Write to JSON \n",
    "* Filtering \n",
    "* Sorting \n",
    "* Generate new rows \n",
    "* Aggregations\n",
    "* Grouping "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "### Import Pyspark package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "source": [
    "### Initialize SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "\t.appName(\"Lesson 2 Spark Exercise 01\")\\\n",
    "\t.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Read Event types CSV file \n",
    "\n",
    "Requirements: \n",
    "* Read source data from S3 bucket: event_types.csv -> path: s3a://wix-pyspark-labs/data/war-data/event_types.csv\n",
    "* Use modes. Throws an exception when it meets corrupted records.\n",
    "* Apply delimiter option via '|'\n",
    "* Rename 'event type' column to 'event_type'\n",
    "\n",
    "Expected table:\n",
    "```\n",
    "+---+--------------+\n",
    "| id|    event_type|\n",
    "+---+--------------+\n",
    "|  1|          kill|\n",
    "|...|          ... |\n",
    "+---+--------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEventTypes = spark.read \\\n",
    ".format(\"csv\") \\\n",
    ".option(\"header\",\"true\") \\\n",
    ".option(\"mode\", \"FAILFAST\") \\\n",
    ".option(\"delimiter\", \"|\") \\\n",
    ".load(\"event_types.csv\") \\\n",
    ".withColumnRenamed(\"event type\", \"event_type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: Show the existing schema on the current DataFrame. Then print all the data. \n",
    "\n",
    "Please provide the code for the following task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- event_type: string (nullable = true)\n",
      "\n",
      "+---+--------------+\n",
      "| id|    event_type|\n",
      "+---+--------------+\n",
      "|  1|          kill|\n",
      "|  2|         wound|\n",
      "|  3|           hit|\n",
      "|  4|          shot|\n",
      "|  5|       misfire|\n",
      "|  6|   close range|\n",
      "|  7|avgerage range|\n",
      "|  8|    long range|\n",
      "+---+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfEventTypes.printSchema()\n",
    "dfEventTypes.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Read Waapon types CSV file \n",
    "\n",
    "Requirements: \n",
    "* Read source data from S3 bucket: weapon_types.csv -> path: `s3a://wix-pyspark-labs/data/war-data/weapon_types.csv`\n",
    "* Use modes. Throws an exception when it meets corrupted records.\n",
    "* Add custom schema: \n",
    "    * 'in range' should be int type value\n",
    "* Rename 'name', 'in range' columns to 'weapon_name','weapon_range'.\n",
    "\n",
    "Expected table:\n",
    "```\n",
    "+---+--------------+------------+\n",
    "| id|   weapon_name|weapon_range|\n",
    "+---+--------------+------------+\n",
    "|  1|          m 16|        2000|\n",
    "|  2|           ...|         ...|\n",
    "+---+--------------+------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: Create a new custom schema 'weaponTypesSchema' on the current DataFrame\n",
    "\n",
    "Please provide the code for the following task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType\n",
    "\n",
    "weaponTypesSchema =  StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"weapon_name\", StringType(), True),\n",
    "    StructField(\"weapon_range\", IntegerType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: Read Waapon types CSV file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfWeaponTypes = spark.read \\\n",
    ".format(\"csv\") \\\n",
    ".option(\"header\",\"true\") \\\n",
    ".option(\"mode\", \"FAILFAST\") \\\n",
    ".schema(weaponTypesSchema) \\\n",
    ".load(\"weapon_types.csv\") \\\n",
    ".withColumnRenamed(\"in range\", \"weapon_range\") \\\n",
    ".withColumnRenamed(\"name\", \"weapon_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: Show the existing schema on the current DataFrame. Then print all the data.\n",
    "\n",
    "Please provide the code for the following task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- weapon_name: string (nullable = true)\n",
      " |-- weapon_range: integer (nullable = true)\n",
      "\n",
      "+---+--------------+------------+\n",
      "| id|   weapon_name|weapon_range|\n",
      "+---+--------------+------------+\n",
      "|  1|          m 16|        2000|\n",
      "|  2|           uzi|         200|\n",
      "|  3|           akm|        2200|\n",
      "|  4|      revolver|         100|\n",
      "|  5|Smith & Wesson|         150|\n",
      "+---+--------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfWeaponTypes.printSchema()\n",
    "dfWeaponTypes.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Read Soldiers JSON file \n",
    "\n",
    "\n",
    "Requirements: \n",
    "* Read source data from S3 bucket: soldiers.json -> path: S3://\n",
    "* Use modes. Throws an exception when it meets corrupted records.\n",
    "* Use inferSchema.\n",
    "* Rename 'name' column to 'soldier_name'.\n",
    "\n",
    "Expected table:\n",
    "```\n",
    "+---+-------------------+------+\n",
    "| id|       soldier_name|salary|\n",
    "+---+-------------------+------+\n",
    "|  1|   Haegon Blackfyre| 18477|\n",
    "+---+-------------------+------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSoldiers = spark.read \\\n",
    ".format(\"json\") \\\n",
    ".option(\"mode\", \"FAILFAST\") \\\n",
    ".option(\"inferSchema\", \"true\") \\\n",
    ".load(\"soldiers.json\") \\\n",
    ".withColumnRenamed(\"name\", \"soldier_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: Show the existing schema on the current DataFrame. Then print all the data.\n",
    "\n",
    "Please provide the code for the following task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- soldier_name: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n",
      "+---+-------------------+------+\n",
      "| id|       soldier_name|salary|\n",
      "+---+-------------------+------+\n",
      "|  1|   Haegon Blackfyre| 18477|\n",
      "|  2|   Walder Goodbrook| 11371|\n",
      "|  3|              Quent| 18689|\n",
      "|  4|        Androw Frey| 13961|\n",
      "|  5|         Blind Doss| 18662|\n",
      "|  6|    Victaria Tyrell| 13073|\n",
      "|  7|Belaquo Bonebreaker| 16006|\n",
      "|  8|       Mariya Darry| 17818|\n",
      "|  9|    Alyn Connington| 18486|\n",
      "| 10|             Lharys| 11102|\n",
      "+---+-------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfSoldiers.printSchema()\n",
    "dfSoldiers.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Read raw data JSON file \n",
    "\n",
    "\n",
    "Requirements: \n",
    "* Read source data from S3 bucket: raw_data.json -> path: S3://\n",
    "* Use modes. Throws an exception when it meets corrupted records.\n",
    "* Add custom schema.\n",
    "\n",
    "\n",
    "\n",
    "Expected schema:\n",
    "```\n",
    "root\n",
    " |-- distance: double (nullable = true)\n",
    " |-- eventId: integer (nullable = true)\n",
    " |-- soldierId: integer (nullable = true)\n",
    " |-- type: integer (nullable = true)\n",
    " |-- weaponId: integer (nullable = true)\n",
    " |-- when: double (nullable = true)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: Create a new custom schema on the current DataFrameÂ¶\n",
    "\n",
    "Please provide the code for the following task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType\n",
    "\n",
    "rawDataSchema =  StructType([\n",
    "    StructField(\"distance\", DoubleType(), False),\n",
    "    StructField(\"eventId\", IntegerType(), False),\n",
    "    StructField(\"soldierId\", IntegerType(), False),\n",
    "    StructField(\"type\", IntegerType(), False),\n",
    "    StructField(\"weaponId\", IntegerType(), False),\n",
    "    StructField(\"when\", DoubleType(), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: Read raw data JSON file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRawData = spark.read \\\n",
    ".format(\"json\") \\\n",
    ".option(\"mode\", \"FAILFAST\") \\\n",
    ".schema(rawDataSchema) \\\n",
    ".load(\"raw_data.json\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: Show the existing schema on the current DataFrame. Then print all data.\n",
    "\n",
    "Please provide the code for the following task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- distance: double (nullable = true)\n",
      " |-- eventId: integer (nullable = true)\n",
      " |-- soldierId: integer (nullable = true)\n",
      " |-- type: integer (nullable = true)\n",
      " |-- weaponId: integer (nullable = true)\n",
      " |-- when: double (nullable = true)\n",
      "\n",
      "+------------------+-------+---------+----+--------+-----------------+\n",
      "|          distance|eventId|soldierId|type|weaponId|             when|\n",
      "+------------------+-------+---------+----+--------+-----------------+\n",
      "| 699.2676057033572|      1|        9|   8|       1|1.563061295302E12|\n",
      "| 235.0068658232094|      2|        4|   4|       2|1.563061295458E12|\n",
      "|345.48506612195996|      3|        9|   4|       2|1.563061295561E12|\n",
      "|391.70559819126726|      4|        1|   4|       3|1.563061295661E12|\n",
      "| 827.2495155710195|      5|        2|   7|       3|1.563061295778E12|\n",
      "| 78.52588556109919|      6|        8|   1|       4|1.563061295884E12|\n",
      "| 90.40024953001647|      7|        2|   3|       2|1.563061295985E12|\n",
      "| 28.29980077487848|      8|        3|   8|       2|1.563061296089E12|\n",
      "| 690.8141219504818|      9|        6|   5|       4|1.563061296191E12|\n",
      "| 715.5096147977694|     10|        2|   4|       4|1.563061296303E12|\n",
      "|235.18340224223178|     11|        5|   7|       4|1.563061296419E12|\n",
      "| 50.85247865399056|     12|        9|   8|       4|1.563061296535E12|\n",
      "| 651.8829082841968|     13|       10|   5|       3|1.563061296638E12|\n",
      "|107.34347753026685|     14|        3|   4|       3|1.563061296744E12|\n",
      "| 105.0579714601152|     15|        7|   4|       4|1.563061296846E12|\n",
      "|373.59302508751813|     16|       10|   1|       3|1.563061296952E12|\n",
      "| 922.4720631294632|     17|        1|   3|       2|1.563061297064E12|\n",
      "| 520.5605958234752|     18|        2|   2|       3|1.563061297166E12|\n",
      "| 531.0395176142932|     19|        1|   3|       2|1.563061297271E12|\n",
      "| 992.7969295054354|     20|        7|   5|       4|1.563061297375E12|\n",
      "+------------------+-------+---------+----+--------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfRawData.printSchema()\n",
    "dfRawData.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Rename multiple columns at once\n",
    "* `eventId` into event_id\n",
    "* `soldierId` into soldier_id\n",
    "* `type` into event_type_id\n",
    "* `weaponId` into weapon_id\n",
    "* `when` into epochTimestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRawDataRenamed = dfRawData \\\n",
    ".withColumnRenamed(\"eventId\", \"event_id\") \\\n",
    ".withColumnRenamed(\"soldierId\", \"soldier_id\") \\\n",
    ".withColumnRenamed(\"type\", \"event_type_id\") \\\n",
    ".withColumnRenamed(\"weaponId\", \"weapon_id\") \\\n",
    ".withColumnRenamed(\"when\", \"epochTimestamp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: Show the existing schema on the current DataFrame. Then print all data.\n",
    "\n",
    "Please provide the code for the following task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- distance: double (nullable = true)\n",
      " |-- event_id: integer (nullable = true)\n",
      " |-- soldier_id: integer (nullable = true)\n",
      " |-- event_type_id: integer (nullable = true)\n",
      " |-- weapon_id: integer (nullable = true)\n",
      " |-- epochTimestamp: double (nullable = true)\n",
      "\n",
      "+------------------+--------+----------+-------------+---------+-----------------+\n",
      "|          distance|event_id|soldier_id|event_type_id|weapon_id|   epochTimestamp|\n",
      "+------------------+--------+----------+-------------+---------+-----------------+\n",
      "| 699.2676057033572|       1|         9|            8|        1|1.563061295302E12|\n",
      "| 235.0068658232094|       2|         4|            4|        2|1.563061295458E12|\n",
      "|345.48506612195996|       3|         9|            4|        2|1.563061295561E12|\n",
      "|391.70559819126726|       4|         1|            4|        3|1.563061295661E12|\n",
      "| 827.2495155710195|       5|         2|            7|        3|1.563061295778E12|\n",
      "| 78.52588556109919|       6|         8|            1|        4|1.563061295884E12|\n",
      "| 90.40024953001647|       7|         2|            3|        2|1.563061295985E12|\n",
      "| 28.29980077487848|       8|         3|            8|        2|1.563061296089E12|\n",
      "| 690.8141219504818|       9|         6|            5|        4|1.563061296191E12|\n",
      "| 715.5096147977694|      10|         2|            4|        4|1.563061296303E12|\n",
      "|235.18340224223178|      11|         5|            7|        4|1.563061296419E12|\n",
      "| 50.85247865399056|      12|         9|            8|        4|1.563061296535E12|\n",
      "| 651.8829082841968|      13|        10|            5|        3|1.563061296638E12|\n",
      "|107.34347753026685|      14|         3|            4|        3|1.563061296744E12|\n",
      "| 105.0579714601152|      15|         7|            4|        4|1.563061296846E12|\n",
      "|373.59302508751813|      16|        10|            1|        3|1.563061296952E12|\n",
      "| 922.4720631294632|      17|         1|            3|        2|1.563061297064E12|\n",
      "| 520.5605958234752|      18|         2|            2|        3|1.563061297166E12|\n",
      "| 531.0395176142932|      19|         1|            3|        2|1.563061297271E12|\n",
      "| 992.7969295054354|      20|         7|            5|        4|1.563061297375E12|\n",
      "+------------------+--------+----------+-------------+---------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfRawDataRenamed.printSchema()\n",
    "dfRawDataRenamed.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Add `timestamp` new column via UDF to dfRawData \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "dfRawData = dfRawDataRenamed.withColumn(\"timestamp\",F.to_timestamp(dfRawDataRenamed[\"epochTimestamp\"]/1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: Print all the data `using truncate`\n",
    "\n",
    "Please provide the code for the following task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------+----------+-------------+---------+-----------------+-----------------------+\n",
      "|distance          |event_id|soldier_id|event_type_id|weapon_id|epochTimestamp   |timestamp              |\n",
      "+------------------+--------+----------+-------------+---------+-----------------+-----------------------+\n",
      "|699.2676057033572 |1       |9         |8            |1        |1.563061295302E12|2019-07-14 02:41:35.302|\n",
      "|235.0068658232094 |2       |4         |4            |2        |1.563061295458E12|2019-07-14 02:41:35.458|\n",
      "|345.48506612195996|3       |9         |4            |2        |1.563061295561E12|2019-07-14 02:41:35.561|\n",
      "|391.70559819126726|4       |1         |4            |3        |1.563061295661E12|2019-07-14 02:41:35.661|\n",
      "|827.2495155710195 |5       |2         |7            |3        |1.563061295778E12|2019-07-14 02:41:35.778|\n",
      "|78.52588556109919 |6       |8         |1            |4        |1.563061295884E12|2019-07-14 02:41:35.884|\n",
      "|90.40024953001647 |7       |2         |3            |2        |1.563061295985E12|2019-07-14 02:41:35.985|\n",
      "|28.29980077487848 |8       |3         |8            |2        |1.563061296089E12|2019-07-14 02:41:36.089|\n",
      "|690.8141219504818 |9       |6         |5            |4        |1.563061296191E12|2019-07-14 02:41:36.191|\n",
      "|715.5096147977694 |10      |2         |4            |4        |1.563061296303E12|2019-07-14 02:41:36.303|\n",
      "|235.18340224223178|11      |5         |7            |4        |1.563061296419E12|2019-07-14 02:41:36.419|\n",
      "|50.85247865399056 |12      |9         |8            |4        |1.563061296535E12|2019-07-14 02:41:36.535|\n",
      "|651.8829082841968 |13      |10        |5            |3        |1.563061296638E12|2019-07-14 02:41:36.638|\n",
      "|107.34347753026685|14      |3         |4            |3        |1.563061296744E12|2019-07-14 02:41:36.744|\n",
      "|105.0579714601152 |15      |7         |4            |4        |1.563061296846E12|2019-07-14 02:41:36.846|\n",
      "|373.59302508751813|16      |10        |1            |3        |1.563061296952E12|2019-07-14 02:41:36.952|\n",
      "|922.4720631294632 |17      |1         |3            |2        |1.563061297064E12|2019-07-14 02:41:37.064|\n",
      "|520.5605958234752 |18      |2         |2            |3        |1.563061297166E12|2019-07-14 02:41:37.166|\n",
      "|531.0395176142932 |19      |1         |3            |2        |1.563061297271E12|2019-07-14 02:41:37.271|\n",
      "|992.7969295054354 |20      |7         |5            |4        |1.563061297375E12|2019-07-14 02:41:37.375|\n",
      "+------------------+--------+----------+-------------+---------+-----------------+-----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfRawData.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Register as a temporary views 'rawTable' based create DataFrames\n",
    "Please provide the code for the following task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfWeaponTypes.createOrReplaceTempView(\"weaponTypes\")\n",
    "dfEventTypes.createOrReplaceTempView(\"eventTypes\")\n",
    "dfSoldiers.createOrReplaceTempView(\"soldiers\")\n",
    "dfRawData.createOrReplaceTempView(\"rawData\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Create new rows based existing row data\n",
    "\n",
    "Create the rows based event types:\n",
    "\n",
    "```\n",
    "+---+--------------+\n",
    "| id|    event_type|\n",
    "+---+--------------+\n",
    "|  1|          kill|\n",
    "|  2|         wound|\n",
    "|  3|           hit|\n",
    "|  4|          shot|\n",
    "|  5|       misfire|\n",
    "|  6|   close range|\n",
    "|  7|avgerage range|\n",
    "|  8|    long range|\n",
    "+---+--------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: Create findEventType function. The function should apply filter and and change value. The return dataframe.\n",
    "\n",
    "3 parameters: df - rawdata dataFrame, eventTypes - array of events, selected_eventType."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findEventType(df, eventTypes, selected_eventType):\n",
    "    return df.filter((df[\"event_type_id\"]).isin(eventTypes)).withColumn(\"event_type_id\",F.lit(selected_eventType))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: Create new rows based existing row data through created function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfEventType3 = findEventType(dfRawData, [1,2], 3)\n",
    "dfEventType4 = findEventType(dfRawData, [1,2,3,6,7,8], 4)\n",
    "\n",
    "\n",
    "dfRawAddedData = dfRawData \\\n",
    "    .union(dfEventType3) \\\n",
    "    .union(dfEventType4) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Join all file types\n",
    "* Create Join and Drop the columns 'ID' after the join\n",
    "* Join with: dfRawData with dfSoldiers, dfWeaponTypes and dfEventTypes\n",
    "* Specify dfRawData left DataFrame and join the right in the JOIN expressions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRawDataJoined = dfRawAddedData \\\n",
    ".join(dfSoldiers, dfRawData[\"soldier_id\"] == dfSoldiers[\"id\"]) \\\n",
    ".drop(\"id\") \\\n",
    ".join(dfWeaponTypes, dfRawData[\"weapon_id\"] == dfWeaponTypes[\"id\"]) \\\n",
    ".drop(\"id\") \\\n",
    ".join(dfEventTypes, dfRawData[\"event_type_id\"] == dfEventTypes[\"id\"]) \\\n",
    ".drop(\"id\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: Print total count\n",
    "\n",
    "Then print selected columns: \n",
    "* distance\n",
    "* soldier_name\n",
    "* event_id\n",
    "* event_type_id\n",
    "* event_type\n",
    "* weapon_id\n",
    "* weapon_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfRawDataJoined.count())\n",
    "dfRawDataJoined.select(F.col(\"distance\"), \\\n",
    "                       F.col(\"soldier_name\"), \\\n",
    "                       F.col(\"event_id\"), \\\n",
    "                       F.col(\"event_type_id\"), \\\n",
    "                       F.col(\"event_type\"), \\\n",
    "                       F.col(\"weapon_id\"), \\\n",
    "                       F.col(\"weapon_name\")\n",
    "                      ).show(n=1000, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Write JSON files \n",
    "\n",
    "* Create a `single JSON file` from multiple partitions in Amazon S3\n",
    "* Overwrite files \n",
    "* S3 path: S3 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathtarget = 'enriched_data.json'\n",
    "\n",
    "dfRawDataJoined \\\n",
    ".coalesce(1) \\\n",
    ".write \\\n",
    ".mode('overwrite') \\\n",
    ".format('json') \\\n",
    ".json(pathtarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
