{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks:\n",
    "* Create custom schema for json files\n",
    "* Read files \n",
    "* Add new column via UDF - timestamp \n",
    "* Add new column - Solder's High salary \n",
    "* Rename column \n",
    "* Append rows (contatinatin) \n",
    "* Join all file types \n",
    "* Write to JSON and Parquet\n",
    "* Filter \n",
    "* Sorting \n",
    "* Generate new rows \n",
    "* Getting unique rows \n",
    "\n",
    "\n",
    "* Aggregations\n",
    "* Grouping "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "### Import Pyspark package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "source": [
    "### Initialize SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "\t.appName(\"Lesson 2 Spark Exercise 01\")\\\n",
    "\t.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Event types CSV file \n",
    "\n",
    "* read from S3 buckets \n",
    "* use modes \n",
    "* use delimiter option via '|'\n",
    "Files:\n",
    "* event_types.csv -> path: S3://"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEventTypes = spark.read \\\n",
    ".format(\"csv\") \\\n",
    ".option(\"header\",\"true\") \\\n",
    ".option(\"mode\", \"FAILFAST\") \\\n",
    ".option(\"delimiter\", \"|\") \\\n",
    ".load(\"event_types.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- event type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task: Show the existing schema on the current DataFrame¶\n",
    "# Please provide the code for the following task:\n",
    "    \n",
    "dfEventTypes.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+\n",
      "| id|    event type|\n",
      "+---+--------------+\n",
      "|  1|          kill|\n",
      "|  2|         wound|\n",
      "|  3|           hit|\n",
      "|  4|          shot|\n",
      "|  5|       misfire|\n",
      "|  6|   close range|\n",
      "|  7|avgerage range|\n",
      "|  8|    long range|\n",
      "+---+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task: Print all the data\n",
    "# Please provide the code for the following task:\n",
    "\n",
    "dfEventTypes.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Waapon types CSV file \n",
    "\n",
    "* read from S3 buckets \n",
    "* use modes \n",
    "* add custom schema . in range should be int value\n",
    "Files:\n",
    "* weapon_types.csv -> path: S3://"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfWeaponTypes = spark.read \\\n",
    ".format(\"csv\") \\\n",
    ".option(\"header\",\"true\") \\\n",
    ".option(\"mode\", \"FAILFAST\") \\\n",
    ".load(\"weapon_types.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- in range: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task: Show the existing schema on the current DataFrame¶\n",
    "# Please provide the code for the following task:\n",
    "    \n",
    "dfWeaponTypes.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+--------+\n",
      "| id|          name|in range|\n",
      "+---+--------------+--------+\n",
      "|  1|          m 16|    2000|\n",
      "|  2|           uzi|     200|\n",
      "|  3|           akm|    2200|\n",
      "|  4|      revolver|     100|\n",
      "|  5|Smith & Wesson|     150|\n",
      "+---+--------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task: Print all the data\n",
    "# Please provide the code for the following task:\n",
    "\n",
    "dfWeaponTypes.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename column 'in range' into range "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfWeaponTypes = dfWeaponTypes.withColumnRenamed(\"in range\", \"range\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Soldiers JSON file \n",
    "\n",
    "* read from S3 buckets \n",
    "* use modes \n",
    "* USE inferSchema\n",
    "Files:\n",
    "* soldiers.json -> path: S3://"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSoldiers = spark.read \\\n",
    ".format(\"json\") \\\n",
    ".option(\"mode\", \"FAILFAST\") \\\n",
    ".option(\"inferSchema\", \"true\") \\\n",
    ".load(\"soldiers.json\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task: Show the existing schema on the current DataFrame¶\n",
    "# Please provide the code for the following task:\n",
    "dfSoldiers.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+------+\n",
      "| id|               name|salary|\n",
      "+---+-------------------+------+\n",
      "|  1|   Haegon Blackfyre| 18477|\n",
      "|  2|   Walder Goodbrook| 11371|\n",
      "|  3|              Quent| 18689|\n",
      "|  4|        Androw Frey| 13961|\n",
      "|  5|         Blind Doss| 18662|\n",
      "|  6|    Victaria Tyrell| 13073|\n",
      "|  7|Belaquo Bonebreaker| 16006|\n",
      "|  8|       Mariya Darry| 17818|\n",
      "|  9|    Alyn Connington| 18486|\n",
      "| 10|             Lharys| 11102|\n",
      "+---+-------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task: Print all the data\n",
    "# Please provide the code for the following task:\n",
    "\n",
    "dfSoldiers.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read raw data JSON file \n",
    "\n",
    "* read from S3 buckets \n",
    "* use modes \n",
    "* * add custom schema . when should be int value, \n",
    "Files:\n",
    "* raw_data.json -> path: S3://"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Create a new custom schema on the current DataFrame¶\n",
    "# Please provide the code for the following task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType\n",
    "\n",
    "rawDataSchema =  StructType([\n",
    "    StructField(\"distance\", DoubleType(), False),\n",
    "    StructField(\"eventId\", IntegerType(), False),\n",
    "    StructField(\"soldierId\", IntegerType(), False),\n",
    "    StructField(\"type\", IntegerType(), False),\n",
    "    StructField(\"weaponId\", IntegerType(), False),\n",
    "    StructField(\"when\", DoubleType(), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRawData = spark.read \\\n",
    ".format(\"json\") \\\n",
    ".option(\"mode\", \"FAILFAST\") \\\n",
    ".schema(rawDataSchema) \\\n",
    ".load(\"raw_data.json\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- distance: double (nullable = true)\n",
      " |-- eventId: integer (nullable = true)\n",
      " |-- soldierId: integer (nullable = true)\n",
      " |-- type: integer (nullable = true)\n",
      " |-- weaponId: integer (nullable = true)\n",
      " |-- when: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task: Show the existing schema on the current DataFrame¶\n",
    "# Please provide the code for the following task:\n",
    "    \n",
    "dfRawData.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+---------+----+--------+-----------------+\n",
      "|          distance|eventId|soldierId|type|weaponId|             when|\n",
      "+------------------+-------+---------+----+--------+-----------------+\n",
      "| 699.2676057033572|      1|        9|   8|      10|1.563061295302E12|\n",
      "| 235.0068658232094|      2|        4|   4|       2|1.563061295458E12|\n",
      "|345.48506612195996|      3|        9|   4|       2|1.563061295561E12|\n",
      "|391.70559819126726|      4|        1|   4|       3|1.563061295661E12|\n",
      "| 827.2495155710195|      5|        2|   7|       3|1.563061295778E12|\n",
      "| 78.52588556109919|      6|        8|   1|       7|1.563061295884E12|\n",
      "| 90.40024953001647|      7|        2|   3|       9|1.563061295985E12|\n",
      "| 28.29980077487848|      8|        3|   8|       9|1.563061296089E12|\n",
      "| 690.8141219504818|      9|        6|   5|       7|1.563061296191E12|\n",
      "| 715.5096147977694|     10|        2|   4|       4|1.563061296303E12|\n",
      "|235.18340224223178|     11|        5|   7|       7|1.563061296419E12|\n",
      "| 50.85247865399056|     12|        9|   8|       4|1.563061296535E12|\n",
      "| 651.8829082841968|     13|       10|   5|       8|1.563061296638E12|\n",
      "|107.34347753026685|     14|        3|   4|       3|1.563061296744E12|\n",
      "| 105.0579714601152|     15|        7|   4|       4|1.563061296846E12|\n",
      "|373.59302508751813|     16|       10|   1|       8|1.563061296952E12|\n",
      "| 922.4720631294632|     17|        1|   3|       2|1.563061297064E12|\n",
      "| 520.5605958234752|     18|        2|   2|       8|1.563061297166E12|\n",
      "| 531.0395176142932|     19|        1|   3|       2|1.563061297271E12|\n",
      "| 992.7969295054354|     20|        7|   5|       7|1.563061297375E12|\n",
      "+------------------+-------+---------+----+--------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task: Print all the data\n",
    "# Please provide the code for the following task:\n",
    "\n",
    "dfRawData.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename multiple columns at once\n",
    "* `type` into weaponType\n",
    "* `when` into epochTimestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRawDataRenamed = dfRawData \\\n",
    ".withColumnRenamed(\"type\", \"weaponType\") \\\n",
    ".withColumnRenamed(\"when\", \"epochTimestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- distance: double (nullable = true)\n",
      " |-- eventId: integer (nullable = true)\n",
      " |-- soldierId: integer (nullable = true)\n",
      " |-- weaponType: integer (nullable = true)\n",
      " |-- weaponId: integer (nullable = true)\n",
      " |-- epochTimestamp: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfRawDataRenamed.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+---------+----------+--------+-----------------+\n",
      "|          distance|eventId|soldierId|weaponType|weaponId|   epochTimestamp|\n",
      "+------------------+-------+---------+----------+--------+-----------------+\n",
      "| 699.2676057033572|      1|        9|         8|      10|1.563061295302E12|\n",
      "| 235.0068658232094|      2|        4|         4|       2|1.563061295458E12|\n",
      "|345.48506612195996|      3|        9|         4|       2|1.563061295561E12|\n",
      "|391.70559819126726|      4|        1|         4|       3|1.563061295661E12|\n",
      "| 827.2495155710195|      5|        2|         7|       3|1.563061295778E12|\n",
      "| 78.52588556109919|      6|        8|         1|       7|1.563061295884E12|\n",
      "| 90.40024953001647|      7|        2|         3|       9|1.563061295985E12|\n",
      "| 28.29980077487848|      8|        3|         8|       9|1.563061296089E12|\n",
      "| 690.8141219504818|      9|        6|         5|       7|1.563061296191E12|\n",
      "| 715.5096147977694|     10|        2|         4|       4|1.563061296303E12|\n",
      "|235.18340224223178|     11|        5|         7|       7|1.563061296419E12|\n",
      "| 50.85247865399056|     12|        9|         8|       4|1.563061296535E12|\n",
      "| 651.8829082841968|     13|       10|         5|       8|1.563061296638E12|\n",
      "|107.34347753026685|     14|        3|         4|       3|1.563061296744E12|\n",
      "| 105.0579714601152|     15|        7|         4|       4|1.563061296846E12|\n",
      "|373.59302508751813|     16|       10|         1|       8|1.563061296952E12|\n",
      "| 922.4720631294632|     17|        1|         3|       2|1.563061297064E12|\n",
      "| 520.5605958234752|     18|        2|         2|       8|1.563061297166E12|\n",
      "| 531.0395176142932|     19|        1|         3|       2|1.563061297271E12|\n",
      "| 992.7969295054354|     20|        7|         5|       7|1.563061297375E12|\n",
      "+------------------+-------+---------+----------+--------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfRawDataRenamed.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add new column via UDF - timestamp \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "dfRawData = dfRawDataRenamed.withColumn(\"timestamp\",F.to_timestamp(dfRawDataRenamed[\"epochTimestamp\"]/1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+---------+----------+--------+-----------------+-----------------------+\n",
      "|distance          |eventId|soldierId|weaponType|weaponId|epochTimestamp   |timestamp              |\n",
      "+------------------+-------+---------+----------+--------+-----------------+-----------------------+\n",
      "|699.2676057033572 |1      |9        |8         |10      |1.563061295302E12|2019-07-14 02:41:35.302|\n",
      "|235.0068658232094 |2      |4        |4         |2       |1.563061295458E12|2019-07-14 02:41:35.458|\n",
      "|345.48506612195996|3      |9        |4         |2       |1.563061295561E12|2019-07-14 02:41:35.561|\n",
      "|391.70559819126726|4      |1        |4         |3       |1.563061295661E12|2019-07-14 02:41:35.661|\n",
      "|827.2495155710195 |5      |2        |7         |3       |1.563061295778E12|2019-07-14 02:41:35.778|\n",
      "|78.52588556109919 |6      |8        |1         |7       |1.563061295884E12|2019-07-14 02:41:35.884|\n",
      "|90.40024953001647 |7      |2        |3         |9       |1.563061295985E12|2019-07-14 02:41:35.985|\n",
      "|28.29980077487848 |8      |3        |8         |9       |1.563061296089E12|2019-07-14 02:41:36.089|\n",
      "|690.8141219504818 |9      |6        |5         |7       |1.563061296191E12|2019-07-14 02:41:36.191|\n",
      "|715.5096147977694 |10     |2        |4         |4       |1.563061296303E12|2019-07-14 02:41:36.303|\n",
      "|235.18340224223178|11     |5        |7         |7       |1.563061296419E12|2019-07-14 02:41:36.419|\n",
      "|50.85247865399056 |12     |9        |8         |4       |1.563061296535E12|2019-07-14 02:41:36.535|\n",
      "|651.8829082841968 |13     |10       |5         |8       |1.563061296638E12|2019-07-14 02:41:36.638|\n",
      "|107.34347753026685|14     |3        |4         |3       |1.563061296744E12|2019-07-14 02:41:36.744|\n",
      "|105.0579714601152 |15     |7        |4         |4       |1.563061296846E12|2019-07-14 02:41:36.846|\n",
      "|373.59302508751813|16     |10       |1         |8       |1.563061296952E12|2019-07-14 02:41:36.952|\n",
      "|922.4720631294632 |17     |1        |3         |2       |1.563061297064E12|2019-07-14 02:41:37.064|\n",
      "|520.5605958234752 |18     |2        |2         |8       |1.563061297166E12|2019-07-14 02:41:37.166|\n",
      "|531.0395176142932 |19     |1        |3         |2       |1.563061297271E12|2019-07-14 02:41:37.271|\n",
      "|992.7969295054354 |20     |7        |5         |7       |1.563061297375E12|2019-07-14 02:41:37.375|\n",
      "+------------------+-------+---------+----------+--------+-----------------+-----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task: Print all the data `using truncate`\n",
    "# Please provide the code for the following task:\n",
    "dfRawData.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Register as a temporary views 'rawTable' based create DataFrames\n",
    "Please provide the code for the following task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfWeaponTypes.createOrReplaceTempView(\"weaponTypes\")\n",
    "dfEventTypes.createOrReplaceTempView(\"eventTypes\")\n",
    "dfSoldiers.createOrReplaceTempView(\"soldiers\")\n",
    "dfRawData.createOrReplaceTempView(\"rawData\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join all file types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- distance: double (nullable = true)\n",
      " |-- eventId: integer (nullable = true)\n",
      " |-- event_type: string (nullable = true)\n",
      " |-- soldierId: integer (nullable = true)\n",
      " |-- soldier_name: string (nullable = true)\n",
      " |-- weaponId: integer (nullable = true)\n",
      " |-- weaponType: integer (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      "\n",
      "+------------------+-------+----------+---------+----------------+--------+----------+-----------------------+\n",
      "|distance          |eventId|event_type|soldierId|soldier_name    |weaponId|weaponType|timestamp              |\n",
      "+------------------+-------+----------+---------+----------------+--------+----------+-----------------------+\n",
      "|235.0068658232094 |2      |wound     |4        |Androw Frey     |2       |4         |2019-07-14 02:41:35.458|\n",
      "|345.48506612195996|3      |hit       |9        |Alyn Connington |2       |4         |2019-07-14 02:41:35.561|\n",
      "|391.70559819126726|4      |shot      |1        |Haegon Blackfyre|3       |4         |2019-07-14 02:41:35.661|\n",
      "|827.2495155710195 |5      |misfire   |2        |Walder Goodbrook|3       |7         |2019-07-14 02:41:35.778|\n",
      "+------------------+-------+----------+---------+----------------+--------+----------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Create Inner Join and Drop the columns 'ID' after the join\n",
    "\n",
    "# Inner joins are the default join, so we just need to specify our left DataFrame and join the right in the JOIN expression: \n",
    "\n",
    "\n",
    "dfRawData1 = dfRawData \\\n",
    ".join(dfEventTypes, dfRawData[\"eventId\"] == dfEventTypes[\"id\"]) \\\n",
    ".join(dfWeaponTypes, dfRawData[\"weaponId\"] == dfWeaponTypes[\"id\"]) \\\n",
    ".join(dfSoldiers, dfRawData[\"soldierId\"] == dfSoldiers[\"id\"]) \\\n",
    ".drop(\"id\") \\\n",
    ".select(F.col(\"distance\"), \\\n",
    "        F.col(\"eventId\"), \\\n",
    "        F.col(\"event type\").alias(\"event_type\"), \\\n",
    "        F.col(\"soldierId\"), \\\n",
    "        F.col(\"name\").alias(\"soldier_name\"), \\\n",
    "        F.col(\"weaponId\"), \\\n",
    "        F.col(\"weaponType\"), \\\n",
    "        F.col(\"timestamp\")  \n",
    "      )\n",
    "\n",
    "dfRawData1.printSchema()\n",
    "dfRawData1.show(n=200, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
