{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks:\n",
    "* Create custom schema for json files\n",
    "* Read files \n",
    "* Add new column via UDF - timestamp \n",
    "* Add new column - Solder's High salary \n",
    "* Rename column \n",
    "* Append rows (contatinatin) \n",
    "* Join all file types \n",
    "* Write to JSON \n",
    "* Filtering \n",
    "* Sorting \n",
    "* Generate new rows \n",
    "* Getting unique rows \n",
    "* Aggregations\n",
    "* Grouping "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "### Import Pyspark package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "source": [
    "### Initialize SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "\t.appName(\"Lesson 2 Spark Exercise 01\")\\\n",
    "\t.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Read Event types CSV file \n",
    "\n",
    "Requirements: \n",
    "* Read source data from S3 bucket: event_types.csv -> path: s3a://wix-pyspark-labs/data/war-data/event_types.csv\n",
    "* Use modes. Throws an exception when it meets corrupted records.\n",
    "* Apply delimiter option via '|'\n",
    "* Rename 'event type' column to 'event_type'\n",
    "\n",
    "Expected table:\n",
    "```\n",
    "+---+--------------+\n",
    "| id|    event_type|\n",
    "+---+--------------+\n",
    "|  1|          kill|\n",
    "|...|          ... |\n",
    "+---+--------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: Show the existing schema on the current DataFrame. Then print all the data. \n",
    "\n",
    "Please provide the code for the following task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Read Waapon types CSV file \n",
    "\n",
    "Requirements: \n",
    "* Read source data from S3 bucket: weapon_types.csv -> path: `s3a://wix-pyspark-labs/data/war-data/weapon_types.csv`\n",
    "* Use modes. Throws an exception when it meets corrupted records.\n",
    "* Add custom schema: \n",
    "    * 'in range' should be int type value\n",
    "* Rename 'name', 'in range' columns to 'weapon_name','weapon_range'.\n",
    "\n",
    "Expected table:\n",
    "```\n",
    "+---+--------------+------------+\n",
    "| id|   weapon_name|weapon_range|\n",
    "+---+--------------+------------+\n",
    "|  1|          m 16|        2000|\n",
    "|  2|           ...|         ...|\n",
    "+---+--------------+------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: Create a new custom schema 'weaponTypesSchema' on the current DataFrame\n",
    "\n",
    "Please provide the code for the following task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: Read Waapon types CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: Show the existing schema on the current DataFrame. Then print all the data.\n",
    "\n",
    "Please provide the code for the following task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Read Soldiers JSON file \n",
    "\n",
    "\n",
    "Requirements: \n",
    "* Read source data from S3 bucket: soldiers.json -> path: s3a://wix-pyspark-labs/data/war-data/soldiers.json\n",
    "* Use modes. Throws an exception when it meets corrupted records.\n",
    "* Use inferSchema.\n",
    "* Rename 'name' column to 'soldier_name'.\n",
    "\n",
    "Expected table:\n",
    "```\n",
    "+---+-------------------+------+\n",
    "| id|       soldier_name|salary|\n",
    "+---+-------------------+------+\n",
    "|  1|   Haegon Blackfyre| 18477|\n",
    "+---+-------------------+------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Show the existing schema on the current DataFrame. Then print all the data.\n",
    "\n",
    "# Please provide the code for the following task:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Read raw data JSON file \n",
    "\n",
    "\n",
    "Requirements: \n",
    "* Read source data from S3 bucket: raw_data.json -> path: s3a://wix-pyspark-labs/data/war-data/raw_data.json\n",
    "* Use modes. Throws an exception when it meets corrupted records.\n",
    "* Add custom schema.\n",
    "\n",
    "\n",
    "\n",
    "Expected schema:\n",
    "```\n",
    "root\n",
    " |-- distance: double (nullable = true)\n",
    " |-- eventId: integer (nullable = true)\n",
    " |-- soldierId: integer (nullable = true)\n",
    " |-- type: integer (nullable = true)\n",
    " |-- weaponId: integer (nullable = true)\n",
    " |-- when: double (nullable = true)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: Create a new custom schema on the current DataFrame\n",
    "\n",
    "Please provide the code for the following task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Show the existing schema on the current DataFrame. Then print all data.\n",
    "# Please provide the code for the following task:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Rename multiple columns at once\n",
    "* `eventId` into event_id\n",
    "* `soldierId` into soldier_id\n",
    "* `type` into event_type_id\n",
    "* `weaponId` into weapon_id\n",
    "* `when` into epochTimestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Show the existing schema on the current DataFrame. Then print all data.\n",
    "# Please provide the code for the following task:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Add `timestamp` new column via UDF to dfRawData \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Task: Print all the data `using truncate`\n",
    "# Please provide the code for the following task:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Register as a temporary views 'rawTable' based create DataFrames\n",
    "Please provide the code for the following task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Create new rows based existing row data\n",
    "\n",
    "Create the rows based event types:\n",
    "\n",
    "```\n",
    "+---+--------------+\n",
    "| id|    event_type|\n",
    "+---+--------------+\n",
    "|  1|          kill|\n",
    "|  2|         wound|\n",
    "|  3|           hit|\n",
    "|  4|          shot|\n",
    "|  5|       misfire|\n",
    "|  6|   close range|\n",
    "|  7|avgerage range|\n",
    "|  8|    long range|\n",
    "+---+--------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Create findEventType function. The function should apply filter and and change value. The return dataframe.\n",
    "# 3 parameters: df - rawdata dataFrame, eventTypes - array of events, selected_eventType.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Join all file types\n",
    "* Create Join and Drop the columns 'ID' after the join\n",
    "* Join with: dfRawData with dfSoldiers, dfWeaponTypes and dfEventTypes\n",
    "* Specify dfRawData left DataFrame and join the right in the JOIN expressions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: Print total count\n",
    "\n",
    "Then print selected columns: \n",
    "* distance\n",
    "* soldier_name\n",
    "* event_id\n",
    "* event_type_id\n",
    "* event_type\n",
    "* weapon_id\n",
    "* weapon_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Write JSON files \n",
    "\n",
    "* Create a `single JSON file` from multiple partitions in Amazon S3\n",
    "* Overwrite files \n",
    "* S3 path: S3 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
